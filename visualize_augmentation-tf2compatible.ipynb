{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is mainly from object detection API jupyter notebook and object detection API preprocessor.py\n",
    "from object_detection.core import preprocessor\n",
    "import functools, os\n",
    "from object_detection import inputs\n",
    "from object_detection.core import standard_fields as fields\n",
    "from matplotlib import pyplot as mp\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.float32)#.astype(np.uint8)\n",
    "\n",
    "number_of_repeats = 1 # lot of augmentations have probabilities < 1 will not happen if repeated only once.\n",
    "\n",
    "path=r\"C:\\Tensor Flow for object detection\\TFODCourse\\Tensorflow\\workspace\\images\\resized_800_complete_dataset_mobnet640_augmented\\test\\BackgroundTests_colorA1_3.jpg\"\n",
    "\n",
    "  \n",
    "image2 = Image.open(path)\n",
    "image_np = load_image_into_numpy_array(image2)\n",
    "# UNCOMMENT THIS CODE TO USE YOUR PICTURE\n",
    "#IMAGE = \"\" # add image here\n",
    "#image2 = Image.open(IMAGE)\n",
    "save_to_disk = False\n",
    "directory = 'visualize_augmentation'\n",
    "preprocessing_list = [None, \n",
    "                      (preprocessor.random_horizontal_flip, {}), \n",
    "                      (preprocessor.random_vertical_flip, {}), \n",
    "                      (preprocessor.random_rotation90, {}), \n",
    "                      (preprocessor.random_pixel_value_scale, {}), # slightly changes the values of pixels\n",
    "                      #(preprocessor.RandomJpegQuality , {}),\n",
    "                      (preprocessor.random_image_scale, {}),  \n",
    "                      (preprocessor.random_rgb_to_gray, {}),\n",
    "                      (preprocessor.random_adjust_brightness,{}),\n",
    "                      (preprocessor.random_adjust_contrast, {}),\n",
    "                      (preprocessor.random_adjust_hue, {}),\n",
    "                      (preprocessor.random_adjust_saturation, {}),\n",
    "                      (preprocessor.random_distort_color, {}), # very strong augmentation\n",
    "                      (preprocessor.random_jitter_boxes, {}),\n",
    "                      (preprocessor.random_crop_image, {}), \n",
    "                      (preprocessor.random_pad_image, {}), # changes the pixel values\n",
    "                      #(preprocessor.random_absolute_pad_image, {}),\n",
    "                      (preprocessor.random_crop_pad_image, {}), \n",
    "                      #(preprocessor.random_crop_to_aspect_ratio, {}),\n",
    "                      (preprocessor.random_pad_to_aspect_ratio, {}),\n",
    "                      (preprocessor.random_black_patches, {}),\n",
    "                      #(preprocessor.random_resize_method, {}),\n",
    "                      (preprocessor.resize_to_min_dimension, {}),\n",
    "                      (preprocessor.random_patch_gaussian, {}),\n",
    "                      (preprocessor.scale_boxes_to_pixel_coordinates, {}), \n",
    "                      #(preprocessor.subtract_channel_mean, {}),\n",
    "                      #(preprocessor.random_self_concat_image, {}),\n",
    "                      #(preprocessor.ssd_random_crop, {}),\n",
    "                      #(preprocessor.ssd_random_crop_pad, {}),\n",
    "                      #(preprocessor.ssd_random_crop_fixed_aspect_ratio, {}),\n",
    "                      #(preprocessor.ssd_random_crop_pad_fixed_aspect_ratio, {}),\n",
    "                      #(preprocessor.convert_class_logits_to_softmax, {}),\n",
    "\n",
    "                      # \n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for preprocessing_technique in preprocessing_list:\n",
    "    for i in range(number_of_repeats):\n",
    "         \n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        if preprocessing_technique is  not None:\n",
    "            print(str(preprocessing_technique[0].__name__))\n",
    "        else:\n",
    "            print('Image without augmentation: ')    \n",
    "        if preprocessing_technique is not None:\n",
    "            data_augmentation_options = [preprocessing_technique]\n",
    "        else:\n",
    "            data_augmentation_options = []\n",
    "        data_augmentation_fn = functools.partial(\n",
    "                inputs.augment_input_data,\n",
    "                data_augmentation_options=data_augmentation_options)\n",
    "        tensor_dict = {\n",
    "                fields.InputDataFields.image:\n",
    "                    tf.constant(image_np.astype(np.float32)),\n",
    "                fields.InputDataFields.groundtruth_boxes:\n",
    "                    tf.constant(np.array([[.5, .5, 1., 1.]], np.float32)),\n",
    "                fields.InputDataFields.groundtruth_classes:\n",
    "                    tf.constant(np.array([1.0], np.float32)),\n",
    "            }\n",
    "        augmented_tensor_dict = data_augmentation_fn(tensor_dict=tensor_dict)\n",
    "#        with tf.compat.v1.Session()  as sess:\n",
    "#              augmented_tensor_dict_out = sess.run(augmented_tensor_dict)\n",
    "        plt.figure()\n",
    "        plt.imshow(augmented_tensor_dict[fields.InputDataFields.image].numpy().astype(int))\n",
    "        plt.show()\n",
    "        #print(augmented_tensor_dict[fields.InputDataFields.image].shape)\n",
    "        #print(augmented_tensor_dict[fields.InputDataFields.image].dtype)\n",
    "        #print(augmented_tensor_dict[fields.InputDataFields.image])\n",
    "        \n",
    "        if save_to_disk:\n",
    "            plt.imshow(augmented_tensor_dict_out[fields.InputDataFields.image].astype(int))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            if preprocessing_technique is  not None:\n",
    "                mp.savefig(directory +'/augmentation_'+str(preprocessing_technique[0].__name__)+'_'+str(i)+'.png', dpi=300,  bbox_inches='tight')\n",
    "            else:\n",
    "                mp.savefig(directory + '/no_augmentation.png', dpi=300,  bbox_inches='tight')\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _adjust_brightness(image,delta):\n",
    "      image = tf.image.adjust_brightness(image / 255, delta) * 255\n",
    "      image = tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=255.0)\n",
    "      return image\n",
    "def _adjust_hue(image,delta):\n",
    "      image = tf.image.adjust_hue(image / 255, delta) * 255\n",
    "      image = tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=255.0)\n",
    "      return image\n",
    "def _adjust_saturation(image,saturation_factor):\n",
    "      image = tf.image.adjust_saturation(image / 255, saturation_factor) * 255\n",
    "      image = tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=255.0)\n",
    "      return image\n",
    "def _adjust_contrast(image,contrast_factor):\n",
    "      image = tf.image.adjust_contrast(image / 255, contrast_factor) * 255\n",
    "      image = tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=255.0)\n",
    "      return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path=r\"C:\\Users\\39351\\Desktop\\Images1\\Train_Test_800_completed_dataset\"\n",
    "IMAGE_PATH = os.path.join(path, 'test', '*.jpg')\n",
    "for file in glob.glob(IMAGE_PATH):\n",
    "    image2 = Image.open(file)\n",
    "    image_np = load_image_into_numpy_array(image2)\n",
    "    brightness_delta=.2\n",
    "    Brightness_adjusted_image=_adjust_brightness(image_np,brightness_delta)\n",
    "    Brightness_adjusted_image_np=Brightness_adjusted_image.numpy().astype(int)\n",
    "    print(\"Brightness_adjusted_image\",os.path.basename(file),\"delta=\",brightness_delta)\n",
    "    plt.figure()\n",
    "    plt.imshow(Brightness_adjusted_image_np)\n",
    "    plt.show()\n",
    "    hue_delta=.8\n",
    "    print(\"hue_adjusted_image\",os.path.basename(file),\"delta=\",hue_delta)\n",
    "    hue_adjusted_image=_adjust_hue(image_np,hue_delta)\n",
    "    hue_adjusted_image_np=hue_adjusted_image.numpy().astype(int)\n",
    "    plt.figure()\n",
    "    plt.imshow(hue_adjusted_image_np)\n",
    "    plt.show()\n",
    "    min_sat_factor=.4\n",
    "    print(\"sat_adjusted_image\",os.path.basename(file),\"sat_factor=\",min_sat_factor)\n",
    "    sat_adjusted_image=_adjust_saturation(image_np,sat_factor)\n",
    "    sat_adjusted_image_np=sat_adjusted_image.numpy().astype(int)\n",
    "    plt.figure()\n",
    "    plt.imshow(sat_adjusted_image_np)\n",
    "    plt.show()\n",
    "    max_sat_factor=1.6\n",
    "    print(\"sat_adjusted_image\",os.path.basename(file),\"sat_factor=\",max_sat_factor)\n",
    "    sat_adjusted_image=_adjust_saturation(image_np,sat_factor)\n",
    "    sat_adjusted_image_np=sat_adjusted_image.numpy().astype(int)\n",
    "    plt.figure()\n",
    "    plt.imshow(sat_adjusted_image_np)\n",
    "    plt.show()\n",
    "    min_Contrast_factor=.6\n",
    "    print(\"sat_adjusted_image\",os.path.basename(file),\"Contrast_factor=\",min_Contrast_factor)\n",
    "    Contrast_adjusted_image=_adjust_contrast(image_np,Contrast_factor)\n",
    "    Contrast_adjusted_image_np=Contrast_adjusted_image.numpy().astype(int)\n",
    "    plt.figure()\n",
    "    plt.imshow(Contrast_adjusted_image_np)\n",
    "    plt.show()\n",
    "    max_Contrast_factor=1.4\n",
    "    print(\"sat_adjusted_image\",os.path.basename(file),\"Contrast_factor=\",max_Contrast_factor)\n",
    "    Contrast_adjusted_image=_adjust_contrast(image_np,Contrast_factor)\n",
    "    Contrast_adjusted_image_np=Contrast_adjusted_image.numpy().astype(int)\n",
    "    plt.figure()\n",
    "    plt.imshow(Contrast_adjusted_image_np)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_adjusted_image=_adjust_hue(image_np,.02)\n",
    "hue_adjusted_image_np=hue_adjusted_image.numpy().astype(int)\n",
    "plt.figure()\n",
    "plt.imshow(hue_adjusted_image_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_adjusted_image=_adjust_saturation(image_np,1.6)\n",
    "sat_adjusted_image_np=sat_adjusted_image.numpy().astype(int)\n",
    "plt.figure()\n",
    "plt.imshow(sat_adjusted_image_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contrast_adjusted_image=_adjust_contrast(image_np,1.4)\n",
    "Contrast_adjusted_image_np=Contrast_adjusted_image.numpy().astype(int)\n",
    "plt.figure()\n",
    "plt.imshow(Contrast_adjusted_image_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfodj",
   "language": "python",
   "name": "tfodj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
